{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436333c0",
   "metadata": {},
   "source": [
    "$\\textbf{CNN for deteriming beam position for Hodoscope development}$\n",
    "$\\newline$\n",
    "by Tyler Stuck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fdec72",
   "metadata": {},
   "source": [
    "$\\underline{Abstract}$\n",
    "$\\newline \\text{   }$\n",
    "$\\newline$\n",
    "In this work, a machine learing model was developed to predict the position where an incident beam impinges upon the scintillating crystal when given the total number of photons seen by my photomultiplier tube (PMT) array. The data used in this project was collected from Geant4 simulations of a new Hodoscope design currently being developed for the Facility for Rare Isotope Beams (FRIB) at Michigan State. The model was based upon that shown in assignment 03. However, the model in this project is for regression rather than classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02a054",
   "metadata": {},
   "source": [
    "$\\underline{Introduction}$\n",
    "$\\newline \\text{   }$\n",
    "$\\newline$\n",
    "\n",
    "The current hodoscope used at FRIB consists of 32 CsI(Na) scintilating crystals that have a face of area 7.6 cm x 7.6 cm and depth of 5.1 cm. Each crystal is attached to a photomultiplier tube for reading out the produced photons. These 32 crystals are arranged in eight rows of four. The hodoscope reads out the total kinetic energy deposited by an implanted nuclei and, in conjunction with the ionization champer, be used for identification of different charge states [1]. \n",
    "\n",
    "$\\newline$\n",
    "An improved version of the hodoscope is currently being developed. The CsI(Na) scintillating crystals of the same dimension will be still be used. Now a trapezoidal light-guide consiting of PMMA (a type of transparent glass) and a $TiO_2$ (Simulations with different coatings are still on going) coating will be used to direct the produced light into a PMT array. This array consists of a four by four grid of silicon photomultiplier tubes each with a face area of 12 mm x 12 mm.\n",
    "\n",
    "$\\newline$\n",
    "The total number of photons observed by the PMT array is dependent on where the incident beam impinges upon the scintillating crystal. If the beam where to impinge upon the edge of the crystal, then number of photons observed by the array would be less than that seen if the beam impinged upon the center of the crystal. To eliminate the dependence of the beam's impinging position on the number of photons observed we can follow a method provided in [2]. \n",
    "\n",
    "$\\newline$\n",
    "\n",
    "$$ L(Z) = L_m (x, y, Z)C(x,y) $$\n",
    "\n",
    "$\\newline$\n",
    "L(Z) is the output corrected for position. $L_m$ is the original total photon data set, and C is the correcting function. $C(x,y)$ explicitly is the inverse of a function that fits the original photon data set (normalized to the lowest observed number of photons) based on x and y. A fitting function following this procedure was obtained for the new Hodoscope design based on Geant4 simulations. However, to use this type of method based on experimental data we must know where the beam impinges upon the scintillator. Where the beam impinges upon the scintillating crystal is currently unable to be determined using this improved Hodoscope design. Using the CNN proposed in this project, it has been shown that the model can accurately predict where the beam impinges upon the scintillator (average error of less than 1 mm in both the x and y position) based upon the number of photons observed by each of the pmts in the PMT array.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f08fd6",
   "metadata": {},
   "source": [
    "Google Colab Installation of mlinphysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b23e70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running locally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLAB_FOLDER = 'MLP' # change as needed\n",
    "GITHUB_USER  = 'hbprosper'\n",
    "GITHUB_REPO  = 'mlinphysics'\n",
    "GITHUB_FOLDERS = ['mlinphysics']\n",
    "#------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    print('\\nGoogle Drive mounted\\n')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print('\\nRunning locally\\n')\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    MYDRIVE     = '/content/gdrive/MyDrive'\n",
    "    GITHUB_BASE = 'https://raw.githubusercontent.com'\n",
    "    MAIN        = 'refs/heads/main'\n",
    "    GITHUB_PATH = f'{MYDRIVE}/{COLAB_FOLDER}'\n",
    "    #------------------------------------------------------\n",
    "    %cd {GITHUB_PATH}\n",
    "    %rm -f {GITHUB_PATH}/clone2colab.ipynb\n",
    "    !wget -q {GITHUB_BASE}/{GITHUB_USER}/{GITHUB_REPO}/{MAIN}/clone2colab.ipynb\n",
    "    %run {GITHUB_PATH}/clone2colab.ipynb\n",
    "\n",
    "    %pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb438b52",
   "metadata": {},
   "source": [
    "Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c8c306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "\n",
    "# module to access data in Hieracrchical Data Format (HDF or H5 format)\n",
    "import h5py\n",
    "\n",
    "# module to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# module to reimport Python modules\n",
    "import importlib\n",
    "\n",
    "# module for saving/loading serialized Python objects\n",
    "import joblib\n",
    "\n",
    "# module for shell utilities\n",
    "import shutil\n",
    "\n",
    "# ML in physics module\n",
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat\n",
    "import mlinphysics.utils.monitor as mon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095e404",
   "metadata": {},
   "source": [
    "Computational Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5950787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAvailable device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c3594",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Dataset Description}}$\n",
    "$\\newline \\text{  }$\n",
    "\n",
    "The datasets being used in this project were collected from a Geant4 simulation with a single crystal set-up of the new hodoscope design. Prior to conducting this simulation, the optimal angle region of the light-guide was found to be between 61 and 63 degrees or equivalently a distance between the scintillating crystal and the PMT array of 0.7 and 0.8 cm. Within this optimal region there is less tha 0.5% variation of the total number of photons observed by the PMT array. The angle chosen for this simulation was 61.4 degrees or a distance of 0.755 cm between crystal and PMT array. The incident beam was $^{82}Se$ with a charge of 34 and beam energy of 140 MeV/u. The impinging position varied from -35mm to 35mm in steps of 2mm in both the x and y position. For each position combination 1 event was conducted. The following data was collected: beam position and momentum, total produced photons via scintillation, and photons observed by each pmt of the PMT array. \n",
    "\n",
    "$\\newline$\n",
    "\n",
    "The number of photons observed by each PMT is normalized to the total number of photons observed by the PMT array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd31628",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Loading the data sets from files into python}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8021704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-35. -35. -80.   0.   0.  10.]\n",
      " [-35. -33. -80.   0.   0.  10.]\n",
      " [-35. -31. -80.   0.   0.  10.]\n",
      " ...\n",
      " [ 35.  31. -80.   0.   0.  10.]\n",
      " [ 35.  33. -80.   0.   0.  10.]\n",
      " [ 35.  35. -80.   0.   0.  10.]]\n"
     ]
    }
   ],
   "source": [
    "produced_photons_array = np.loadtxt('scan_CsI_Se82_master_produced_photon.dat')\n",
    "absorbed_photons_array = np.loadtxt('scan_CsI_Se82_master_absorbed_photon.dat')\n",
    "observed_photon_array_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_array.dat')\n",
    "observed_photon_total_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_total.dat')\n",
    "beam_position_array = np.loadtxt('scan_CsI_Se82_master_beam_position.dat')\n",
    "\n",
    "#Converting the beam position array to mm (values are currently in cm)\n",
    "beam_position_array = beam_position_array * 10\n",
    "\n",
    "#Normalizing each PMT of the array to the total number of photons seen by the PMTs\n",
    "normalized_PMT_array = np.zeros((1296,16))\n",
    "\n",
    "for i in range (1296):\n",
    "    for m in range (16):\n",
    "        normalized_PMT_array[i][m] = observed_photon_array_array[i][m] / observed_photon_total_array[i]\n",
    "\n",
    "# print (normalized_PMT_array.shape)\n",
    "\n",
    "print(beam_position_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea81c4",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Separating the data sets into training, validating, and testing}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af24113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training idices:  462\n",
      "training position [-11.  25.]\n",
      "training position shape:  (648, 2)\n",
      "training photons [0.06366563 0.07160675 0.07526966 0.07605343 0.05828406 0.06463594\n",
      " 0.06838995 0.06852589 0.05565509 0.06074889 0.06254564 0.06033242\n",
      " 0.0515815  0.05645911 0.05525019 0.05099584]\n"
     ]
    }
   ],
   "source": [
    "# generates a random sequence of integers from 0-1295\n",
    "randomized_indices = np.random.permutation(1296)\n",
    "\n",
    "training_indices = randomized_indices[0:648]\n",
    "validation_indices = randomized_indices[648:972]\n",
    "evaluating_model_indicies = randomized_indices[972:1296]\n",
    "\n",
    "# training, validation, and evaluation photon datasets\n",
    "training_photon_arrays = np.zeros((648,16))\n",
    "validation_photon_arrays = np.zeros((324,16))\n",
    "evaluation_photon_arrays = np.zeros((324,16))\n",
    "\n",
    "# training, validation, and evaluation position datasets\n",
    "training_position_arrays = np.zeros((648,2))\n",
    "validation_position_arrays = np.zeros((324,2))\n",
    "evaluation_position_arrays = np.zeros((324,2))\n",
    "\n",
    "for i in range (648):\n",
    "    # filling the training photon datasets\n",
    "    training_photon_arrays[i][:] = normalized_PMT_array[training_indices[i]][:]\n",
    "\n",
    "    # filling the training position datasets\n",
    "    training_position_arrays[i][:] = beam_position_array[training_indices[i], 0:2]\n",
    "    \n",
    "\n",
    "for i in range (324):\n",
    "    # filling the validation and evaluation (testing) photon datasets\n",
    "    validation_photon_arrays[i][:] = normalized_PMT_array[validation_indices[i]][:]\n",
    "    evaluation_photon_arrays[i][:] = normalized_PMT_array[evaluating_model_indicies[i]][:]\n",
    "\n",
    "    # filling the validation and evaluation (testing) position datasets\n",
    "    validation_position_arrays[i][:] = beam_position_array[validation_indices[i]][0:2]\n",
    "    evaluation_position_arrays[i][:] = beam_position_array[evaluating_model_indicies[i]][0:2]\n",
    "\n",
    "#reshaping the normalized data so that we have 432 images of 4x4 pixels\n",
    "training_photons = training_photon_arrays.reshape(648, 4, 4)\n",
    "validation_photons = validation_photon_arrays.reshape(324, 4, 4)\n",
    "evaluating_photons = evaluation_photon_arrays.reshape(324, 4, 4)\n",
    "\n",
    "print('training idices: ',training_indices[0])\n",
    "\n",
    "print('training position', training_position_arrays[0][:])\n",
    "\n",
    "print('training position shape: ', training_position_arrays.shape)\n",
    "\n",
    "print ('training photons', training_photon_arrays[0][:])\n",
    "\n",
    "###############################################\n",
    "\n",
    "# REMEMBER THAT IF YOU WANT TO COMPARE THE INDEX THAT YOU GET WITH THE DATA SET,\n",
    "# YOU MUST ADD +1 TO THE INDEX VALUE. THE POSSIBLE NUMBERS RANGE FROM 0 TO 1296-1 (1295)\n",
    "# WHILE THE DATA SET STARTS FROM 1\n",
    "\n",
    "###############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eec6f3",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Preparing the datasets so that they are in the shape of (N, C, H, W)}}$\n",
    "\n",
    "$\\newline$\n",
    "N - number of images\n",
    "$\\newline$\n",
    "C - number of input channels \n",
    "$\\newline$\n",
    "H - height of our image in pixels\n",
    "$\\newline$\n",
    "W - width of our image in pixels \n",
    "$\\\\ \\text{   }$\n",
    "$\\\\$\n",
    "Also changing the data types to tensors and then the type to float in order to match that of the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3982c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training photons\n",
    "training_photons = training_photons.reshape(648, 1, 4, 4)\n",
    "training_photons = torch.from_numpy(training_photons.astype(np.float32))\n",
    "training_position_arrays = torch.from_numpy(training_position_arrays.astype(np.float32))\n",
    "\n",
    "# Validation photons\n",
    "validation_photons = validation_photons.reshape(324, 1, 4, 4)\n",
    "validation_photons = torch.from_numpy(validation_photons.astype(np.float32))\n",
    "validation_position_arrays = torch.from_numpy(validation_position_arrays.astype(np.float32))\n",
    "\n",
    "# Evaluation photons\n",
    "evaluating_photons = evaluating_photons.reshape(324, 1, 4, 4)\n",
    "evaluating_photons = torch.from_numpy(evaluating_photons.astype(np.float32))\n",
    "evaluation_position_arrays = torch.from_numpy(evaluation_position_arrays.astype(np.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58578ce9",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Model Description}}$\n",
    "$\\newline \\text{ }$\n",
    "$\\newline$\n",
    "The model used in this project is based on that shown in Assignment 03. The image consists of normalized photon values in a four by four grid. This grid is then padded by 1 pixel with a value equal to that of the pixel it is next to. Pytorch's Conv2d function was used to convolve the input image. The padding was used to ensure that the convolved image had the same dimension as the original input. The first convolution takes in one input and outputs eight images, the second convolution takes in those eight images and outputs 16 images. The model uses Relu as its activation function (same activation function as that in [2] and in assignment 3). Similarly to assignment 3 the dropout function was used to ensure that the model is not overfitting the data. Unlike the model in assignment 3, the model in this project does not use the maxpool function or a softmax. The first change, is due to the small size of our image 4x4. The second change is due to our outputs being spanning a continuous range from -35 to 35 mm (of course the predicted outputs may deviate between these bounds) rather than discrete categories.\n",
    "\n",
    "Once the final set of images has been obtained, the images are then flattened into a tensor. Once the data has been flattened a linear transformation (Pytorch's .Linear) is applied transforming the 256 inputs to 64 inputs. The Relu activation function is then once again used before a final linear transformation is applied transforming the 64 inputs into two outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef17a9",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Configuration of the model}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e94ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save configuration to file runs/2025-11-28_2007/impinging_position_config.yaml\n",
      "\n",
      "name: impinging_position\n",
      "file:\n",
      "  losses: runs/2025-11-28_2007/impinging_position_losses.csv\n",
      "  params: runs/2025-11-28_2007/impinging_position_params.pth\n",
      "  init_params: runs/2025-11-28_2007/impinging_position_init_params.pth\n",
      "  plots: runs/2025-11-28_2007/impinging_position_plots.png\n",
      "batch_size: 18\n",
      "train_size: 648\n",
      "test_size: 324\n",
      "val_size: 324\n",
      "monitor_step: 27\n",
      "delete: true\n",
      "frac: 0.015\n",
      "n_epochs: 200\n",
      "n_iters_per_epoch: 36\n",
      "n_iterations: 7200\n",
      "n_steps: 4\n",
      "n_iters_per_step: 1800\n",
      "base_lr: 0.001\n",
      "gamma: 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'impinging_position'\n",
    "\n",
    "# choose whether to create or load a configuration file\n",
    "load_existing_config = False\n",
    "\n",
    "if load_existing_config:\n",
    "    config = mlp.Config(f'{model_name}.yaml')\n",
    "else:\n",
    "    # create new config\n",
    "    config = mlp.Config(model_name)\n",
    "\n",
    "    n_images = 1296\n",
    "    batch_size = 18\n",
    "    n_iters_per_epoch = 36 # number of iterations per epoch\n",
    "    train_size = n_iters_per_epoch * batch_size\n",
    "    test_size = 324\n",
    "\n",
    "    val_size = n_images - train_size - test_size\n",
    "\n",
    "    config('batch_size', batch_size)\n",
    "    config('train_size', train_size)\n",
    "    config('test_size', test_size)\n",
    "    config('val_size', val_size)\n",
    "\n",
    "    config('monitor_step', 27) # set monitor training every n\n",
    "    config('delete', True) # delete losses file before training, if True\n",
    "    config('frac', 0.015) # save model if average loss decreases by more than frac percent\n",
    "\n",
    "    config('n_epochs', 200)\n",
    "    config('n_iters_per_epoch', n_iters_per_epoch)\n",
    "    config('n_iterations', config('n_epochs') * config('n_iters_per_epoch'))\n",
    "\n",
    "    config('n_steps', 4) # number of training steps\n",
    "    config('n_iters_per_step', config('n_iterations') // config('n_steps'))\n",
    "    \n",
    "    config('base_lr', 1.e-3) # initial learning rate\n",
    "    config('gamma', 0.8) # learning rate scale factor\n",
    "\n",
    "    print(f'\\nSave configuration to file {config.cfg_filename}\\n')\n",
    "    \n",
    "    config.save()\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db73912",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Getting our data turned into the proper data set so that it can be used with the data loaders}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de159538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "Dataset\n",
      "  shape of x: torch.Size([648, 1, 4, 4])\n",
      "  shape of y: torch.Size([648, 2])\n",
      "\n",
      "training data for validation\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 2])\n",
      "\n",
      "validation data\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 2])\n",
      "\n",
      "test data\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 2])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tmp = torch.tensor(data[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(data[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(targets[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(data[indices])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(targets[indices])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dat)\n",
    "\n",
    "train_size = config('train_size')\n",
    "val_size = config('val_size')\n",
    "test_size = config('test_size')\n",
    "\n",
    "# training dataset (this defines the empirical risk to be minimized)\n",
    "print('training data')\n",
    "train_data = dat.Dataset(training_photons, start = 0, end = train_size, targets = training_position_arrays)\n",
    "\n",
    "# a random subset of the training data to check for overtraining\n",
    "# by comparing with the empirical risk from the validation set\n",
    "\n",
    "print('training data for validation')\n",
    "train_data_val = dat.Dataset(training_photons, start = 0, end = train_size, targets = training_position_arrays, random_sample_size = val_size)\n",
    "\n",
    "# validation dataset (for monitoring training)\n",
    "print('validation data')\n",
    "val_data = dat.Dataset(validation_photons, start = 0, end = val_size, targets = validation_position_arrays)\n",
    "\n",
    "# test dataset\n",
    "print('test data')\n",
    "test_data = dat.Dataset(evaluating_photons, start = 0, end = test_size, targets = evaluation_position_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe662",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Now we include the data loaders}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c798bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data loader\n",
      "train data loader for validation\n",
      "validation data loader\n",
      "test data loader\n"
     ]
    }
   ],
   "source": [
    "print('train data loader')\n",
    "train_loader = dt.DataLoader(train_data, batch_size = config('batch_size'), shuffle = True)\n",
    "\n",
    "print('train data loader for validation')\n",
    "train_loader_val = dt.DataLoader(train_data_val, batch_size = len(train_data_val))\n",
    "\n",
    "print('validation data loader')\n",
    "val_loader = dt.DataLoader(val_data, batch_size = len(val_data))\n",
    "\n",
    "print('test data loader')\n",
    "test_loader = dt.DataLoader(test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16ad27",
   "metadata": {},
   "source": [
    "$\\underline{\\textbf{Build the model}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b2c8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding = 1, dropout = 0.08):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = 2 * padding + 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, \n",
    "                               kernel_size = kernel_size, stride = 1, padding = padding, padding_mode = 'replicate')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class BeamPositionIdentifier(mlp.Model):\n",
    "    def __init__(self, image_size = 4, channels = (1, 8, 16), padding = 1, n_outputs = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        # number of convolutional layers\n",
    "        self.nlayers = len(channels) - 1\n",
    "\n",
    "        #building convolution layers\n",
    "        self.convs = nn.ModuleList(\n",
    "            [ConvBlock(channels[i], channels[i+1], padding)\n",
    "             for i in range(self.nlayers)])\n",
    "        \n",
    "        # computing size after convolutions\n",
    "        final_image_size = image_size\n",
    "        ninputs = channels[-1] * (final_image_size**2)\n",
    "\n",
    "        # Regression (Rather than using maxpool as we want to predict where the beam impinges upon the scintillating crystal (x,y) )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(), # Fllatens a contiguous range of dims into a tensor\n",
    "            nn.Linear(ninputs, 64), # a linear transformation from 256 (16*16 inputs) to 64 outputs\n",
    "            nn.ReLU(), # non linear function\n",
    "            nn.Linear(64, n_outputs) # linear function that transforms 64 to 2 outputs (x,y)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d260c",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Instantiate model}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5c9e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeamPositionIdentifier(\n",
      "  (convs): ModuleList(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.08, inplace=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.08, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (regressor): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "number of parameters:  17826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp)\n",
    "\n",
    "model = BeamPositionIdentifier().to(DEVICE)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print('number of parameters: ', mlp.number_of_parameters(model))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186ba54",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Mean Squared Error Loss function}}$\n",
    "\n",
    "$\\newline$\n",
    "Using the MSE rather than the Average cross entropy loss since we are using regression rather than classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd1354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredErrorLoss():\n",
    "    def __init__(self):\n",
    "        self.loss_function = nn.MSELoss()\n",
    "    def __call__(self, outputs, targets):\n",
    "        return self.loss_function(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8679161",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Instantiate training objects}}$\n",
    "\n",
    "$\\newline$\n",
    "1. optimizer\n",
    "$\\newline$\n",
    "2. scheduler\n",
    "$\\newline$\n",
    "3. objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edb4aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of milestones:          3\n",
      "\n",
      "Step | Milestone | LR\n",
      "-----------------------------\n",
      "   0 |         0 | 1.0e-03   \n",
      "-----------------------------\n",
      "   1 |      1800 | 8.0e-04   \n",
      "   2 |      3600 | 6.4e-04   \n",
      "   3 |      5400 | 5.1e-04   \n",
      "\n",
      "number of iterations:           7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = config('base_lr'))\n",
    "\n",
    "scheduler = mlp.get_steplr_scheduler(optimizer, config)\n",
    "\n",
    "objective = mlp.Objective(model, MeanSquaredErrorLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf8769",
   "metadata": {},
   "source": [
    "$\\underline{\\text{How we are defining accuracy}}$\n",
    "\n",
    "$\\newline$\n",
    "Since our output is continuous values, rather than the discrete categories as with assignment 3 we must redefine how we determine our model's accuracy. Let us consider the distance between predicted and the true value as our accuracy. The function \"accuracy\" takes the outputs from our model and our target values and spits out the average of the discrepancy between the two vectors. So for example if we had (0.0, 0.1) as our output and (0.0, 0.0) as our true value for one run and we only consider one run. Then the accuracy function would output (0.0) for the discrepancy in x and (0.1) for the discrepancy in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "551c7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    \n",
    "    # vector_distance = targets - outputs\n",
    "    # distance = torch.sqrt(torch.sum(vector_distance**2))\n",
    "\n",
    "    abs_discrepancy = torch.abs(targets - outputs)\n",
    "\n",
    "    x_discrepancy = abs_discrepancy[:, 0].mean()\n",
    "    y_discrepancy = abs_discrepancy[:, 1].mean()\n",
    "    \n",
    "    return x_discrepancy, y_discrepancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ca191",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Defining the Trainer}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96a6a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(objective, optimizer, scheduler, train_loader, train_small_loader, val_loader, config):\n",
    "    \n",
    "    # get configuration info\n",
    "    lossfile = config('file/losses')\n",
    "    paramsfile = config('file/params')\n",
    "    step = config('monitor_step')\n",
    "    delete = config('delete')\n",
    "    frac = config('frac')\n",
    "    nepochs = config('n_epochs')\n",
    "    niters = config('n_iterations')\n",
    "\n",
    "    # instantiate objects taht saves MSE losses to a csv file for realtime monitoring\n",
    "\n",
    "    losswriter = mon.LossWriter(niters, lossfile, step = step, delete = delete, frac = frac, model = objective.model, paramsfile = paramsfile)\n",
    "\n",
    "    # instantiate learning rate step scheduler\n",
    "    lrscheduler = mlp.LRStepScheduler(optimizer, scheduler)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # training loop\n",
    "    # ---------------------------------------\n",
    "    ii = -1\n",
    "\n",
    "    for epoch in range (nepochs):\n",
    "        for x, y in train_loader:\n",
    "            ii += 1\n",
    "\n",
    "            # set mode to training so that training-specific\n",
    "            # operations such as dropout, etc., are enabled.\n",
    "            objective.model.train()\n",
    "\n",
    "            # clear all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute empirical risk\n",
    "            R = objective(x,y)\n",
    "\n",
    "            # compute gradients\n",
    "            R.backward()\n",
    "\n",
    "            # take one step downhill in the empirical risk landscape\n",
    "            optimizer.step()\n",
    "\n",
    "            # check wheter to update learning rate\n",
    "            lrscheduler.step()\n",
    "\n",
    "            # I'm alive printout\n",
    "            if (ii % step == 0) or (ii == niters -1):\n",
    "                # compute average losses on training and validation data\n",
    "                t_loss = mlp.compute_avg_loss(objective, train_small_loader)\n",
    "                v_loss = mlp.compute_avg_loss(objective, val_loader)\n",
    "                # return current learning rate\n",
    "                lr = lrscheduler.lr()\n",
    "                # update loss file\n",
    "                losswriter(ii, t_loss, v_loss, lr, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b181096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\tlearning rate:  1.000e-03\n",
      "      1782| 24.76%|00:00:01/00:00:04|1106.2 it/s|        49|1.726e+00|1.698e+00|\n",
      "\t\tlearning rate:  8.000e-04\n",
      "      3591| 49.89%|00:00:03/00:00:03|1133.8 it/s|        99|9.969e-01|1.069e+00|\n",
      "\t\tlearning rate:  6.400e-04\n",
      "      5373| 74.64%|00:00:04/00:00:01|1139.5 it/s|       149|1.036e+00|1.192e+00|\n",
      "\t\tlearning rate:  5.120e-04\n",
      "      7199|100.00%|00:00:06/00:00:00|1145.6 it/s|       199|9.761e-01|1.082e+00|\n",
      "using GUI backend: QtAgg\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp)\n",
    "importlib.reload(mon)\n",
    "\n",
    "train(objective, optimizer, scheduler, train_loader, train_loader_val, val_loader, config)\n",
    "\n",
    "monitor = mon.Monitor(config('file/losses'))\n",
    "#Occasionally this does not show the monitor plot, so I am saving the image, then plotting in the next cell\n",
    "monitor.plot()\n",
    "plt.savefig('monitor.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a39953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11025/2536407948.py:2: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.\n",
      "  plt.imshow(monitor_image)\n",
      "/tmp/ipykernel_11025/2536407948.py:2: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
      "  plt.imshow(monitor_image)\n"
     ]
    }
   ],
   "source": [
    "monitor_image = mpimg.imread('monitor.png')\n",
    "plt.imshow(monitor_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae339b7",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Compute accuracy on test set}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d0401b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average discrepancy on x (mm) :  0.8463555\n",
      "Average discrepancy on y (mm) :  0.7516633\n"
     ]
    }
   ],
   "source": [
    "model.load(config('file/params'))\n",
    "\n",
    "test_x, test_y = next(iter(test_loader))\n",
    "\n",
    "y_pred = model(test_x)\n",
    "\n",
    "#Since acc is a tuple with 2 tensors (accuracy of x and accuracy of 1)\n",
    "acc = accuracy(y_pred, test_y)\n",
    "\n",
    "x_accuracy = acc[0]\n",
    "x_accuracy = x_accuracy.detach().numpy()\n",
    "y_accuracy = acc[1]\n",
    "y_accuracy = y_accuracy.detach().numpy()\n",
    "\n",
    "print('Average discrepancy on x (mm) : ', x_accuracy)\n",
    "print('Average discrepancy on y (mm) : ', y_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1d1a0",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Plots of Predicted and Test data (X)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e473e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting test_y and y_pred into numpy arrays\n",
    "test_y = test_y.detach().numpy()\n",
    "y_pred = y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe6db704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('shape of test_y', test_y.shape)\n",
    "# print('test_y[:][0]', test_y[:,0])\n",
    "# print('test_y', test_y)\n",
    "\n",
    "plt.plot(y_pred[:, 0], test_y[:, 0], 'bs', label = 'test vs predicted x-positions')\n",
    "plt.plot(test_y[:, 0], test_y[:, 0], 'r--', label  = 'predicted x-positions')\n",
    "plt.legend()\n",
    "plt.xlabel(\"predicted x values (mm)\")\n",
    "plt.ylabel(\"test x values (mm)\")\n",
    "\n",
    "plt.savefig('beam_x_position_graph.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ebce940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_beam_position_image = mpimg.imread('beam_x_position_graph.png')\n",
    "plt.imshow(x_beam_position_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e252ccc6",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Plots of Predicted and Test data (Y)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d0603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('shape of test_y', test_y.shape)\n",
    "# print('test_y[:][0]', test_y[:,1])\n",
    "# print('test_y', test_y)\n",
    "\n",
    "plt.plot(y_pred[:, 1], test_y[:, 1], 'bs', label = 'test vs predicted y-positions')\n",
    "plt.plot(test_y[:, 1], test_y[:, 1], 'r--', label  = 'predicted y-positions')\n",
    "plt.legend()\n",
    "plt.xlabel(\"predicted y values (mm)\")\n",
    "plt.ylabel(\"test y values (mm)\")\n",
    "\n",
    "plt.savefig('beam_y_position_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15f45920",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_beam_position_image = mpimg.imread('beam_y_position_graph.png')\n",
    "plt.imshow(y_beam_position_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370bcd8",
   "metadata": {},
   "source": [
    "$\\underline{Summary}$\n",
    "$\\newline$\n",
    "\n",
    "The model is able to accurately predict the location where the beam impinges upon the scintillator. The average discrepancy between the x and y predicted positions and test positions was less than 1 mm. This distance is also less than the step size that was used for the simulation. Based on the two figures we can also see that the predicted locations fit the test values well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea4baf",
   "metadata": {},
   "source": [
    "$\\underline{\\text{References and AI acknowledgement}}$\n",
    "$\\newline \\text{ }$\n",
    "[1] Hodoscope documentation at FRIB: https://wikihost.frib.msu.edu/S800Doc/doku.php?id=detectors\n",
    "$\\newline \\text{ }$\n",
    "[2] Method for removing position dependence of measured scintillation: https://iopscience.iop.org/article/10.1088/1748-0221/20/04/P04025/pdf\n",
    "\n",
    "\n",
    "Chatgpt was used to occassional diagnose errors that might have occured, i.e type issues occasional spelling mistakes. It was also was used to help modify assigment 03 to be for regression rather than classification. Spcifically the self regressor function and not using the maxpool and softmax functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94fecf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
