{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c264416",
   "metadata": {},
   "source": [
    "Goal is to develop machine learning code that takes input photon data from an array of my hodoscope and outputs where the beam impinged on the scintillating crystal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f08fd6",
   "metadata": {},
   "source": [
    "Google Colab Installation of mlinphysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23e70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running locally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLAB_FOLDER = 'MLP' # change as needed\n",
    "GITHUB_USER  = 'hbprosper'\n",
    "GITHUB_REPO  = 'mlinphysics'\n",
    "GITHUB_FOLDERS = ['mlinphysics']\n",
    "#------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    print('\\nGoogle Drive mounted\\n')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print('\\nRunning locally\\n')\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    MYDRIVE     = '/content/gdrive/MyDrive'\n",
    "    GITHUB_BASE = 'https://raw.githubusercontent.com'\n",
    "    MAIN        = 'refs/heads/main'\n",
    "    GITHUB_PATH = f'{MYDRIVE}/{COLAB_FOLDER}'\n",
    "    #------------------------------------------------------\n",
    "    %cd {GITHUB_PATH}\n",
    "    %rm -f {GITHUB_PATH}/clone2colab.ipynb\n",
    "    !wget -q {GITHUB_BASE}/{GITHUB_USER}/{GITHUB_REPO}/{MAIN}/clone2colab.ipynb\n",
    "    %run {GITHUB_PATH}/clone2colab.ipynb\n",
    "\n",
    "    %pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb438b52",
   "metadata": {},
   "source": [
    "Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8c306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "\n",
    "# module to access data in Hieracrchical Data Format (HDF or H5 format)\n",
    "import h5py\n",
    "\n",
    "# module to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# module to reimport Python modules\n",
    "import importlib\n",
    "\n",
    "# module for saving/loading serialized Python objects\n",
    "import joblib\n",
    "\n",
    "# module for shell utilities\n",
    "import shutil\n",
    "\n",
    "# ML in physics module\n",
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat\n",
    "import mlinphysics.utils.monitor as mon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095e404",
   "metadata": {},
   "source": [
    "Computational Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5950787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAvailable device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd31628",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Loading the data sets}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8021704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.5 -3.5 -8.   0.   0.   1. ]\n",
      " [-3.5 -3.3 -8.   0.   0.   1. ]\n",
      " [-3.5 -3.1 -8.   0.   0.   1. ]\n",
      " ...\n",
      " [ 3.5  3.1 -8.   0.   0.   1. ]\n",
      " [ 3.5  3.3 -8.   0.   0.   1. ]\n",
      " [ 3.5  3.5 -8.   0.   0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "produced_photons_array = np.loadtxt('scan_CsI_Se82_master_produced_photon.dat')\n",
    "absorbed_photons_array = np.loadtxt('scan_CsI_Se82_master_absorbed_photon.dat')\n",
    "observed_photon_array_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_array.dat')\n",
    "observed_photon_total_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_total.dat')\n",
    "beam_position_array = np.loadtxt('scan_CsI_Se82_master_beam_position.dat')\n",
    "\n",
    "#Normalizing each PMT of the array to the total number of photons seen by the PMTs\n",
    "normalized_PMT_array = np.zeros((1296,16))\n",
    "\n",
    "for i in range (1296):\n",
    "    for m in range (16):\n",
    "        normalized_PMT_array[i][m] = observed_photon_array_array[i][m] / observed_photon_total_array[i]\n",
    "\n",
    "# print (normalized_PMT_array.shape)\n",
    "\n",
    "print(beam_position_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea81c4",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Separating the data sets into training, validating, and testing}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af24113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training idices:  88\n",
      "training position [-3.1 -0.3]\n",
      "training photons [0.05086854 0.05657435 0.06465793 0.07553629 0.04945106 0.05515902\n",
      " 0.06433353 0.07518174 0.05167094 0.05809661 0.06672925 0.07787819\n",
      " 0.05260253 0.05859327 0.06636537 0.07630137]\n"
     ]
    }
   ],
   "source": [
    "# generates a random sequence of integers from 0-1295\n",
    "randomized_indices = np.random.permutation(1296)\n",
    "\n",
    "training_indices = randomized_indices[0:648]\n",
    "validation_indices = randomized_indices[648:972]\n",
    "evaluating_model_indicies = randomized_indices[972:1296]\n",
    "\n",
    "# training, validation, and evaluation photon datasets\n",
    "training_photon_arrays = np.zeros((648,16))\n",
    "validation_photon_arrays = np.zeros((324,16))\n",
    "evaluation_photon_arrays = np.zeros((324,16))\n",
    "\n",
    "# training, validation, and evaluation position datasets\n",
    "training_position_arrays = np.zeros((648,2))\n",
    "validation_position_arrays = np.zeros((324,2))\n",
    "evaluation_position_arrays = np.zeros((324,2))\n",
    "\n",
    "for i in range (648):\n",
    "    # filling the training photon datasets\n",
    "    training_photon_arrays[i][:] = normalized_PMT_array[training_indices[i]][:]\n",
    "\n",
    "    # filling the training position datasets\n",
    "    training_position_arrays[i][:] = beam_position_array[training_indices[i], 0:2]\n",
    "    \n",
    "\n",
    "for i in range (324):\n",
    "    # filling the validation and evaluation (testing) photon datasets\n",
    "    validation_photon_arrays[i][:] = normalized_PMT_array[validation_indices[i]][:]\n",
    "    evaluation_photon_arrays[i][:] = normalized_PMT_array[evaluating_model_indicies[i]][:]\n",
    "\n",
    "    # filling the validation and evaluation (testing) position datasets\n",
    "    validation_position_arrays[i][:] = beam_position_array[validation_indices[i]][0:2]\n",
    "    evaluation_position_arrays[i][:] = beam_position_array[evaluating_model_indicies[i]][0:2]\n",
    "\n",
    "#reshaping the normalized data so that we have 432 images of 4x4 pixels\n",
    "training_photons = training_photon_arrays.reshape(648, 4, 4)\n",
    "validation_photons = validation_photon_arrays.reshape(324, 4, 4)\n",
    "evaluating_photons = evaluation_photon_arrays.reshape(324, 4, 4)\n",
    "\n",
    "print('training idices: ',training_indices[0])\n",
    "\n",
    "print('training position', training_position_arrays[0][:])\n",
    "\n",
    "print ('training photons', training_photon_arrays[0][:])\n",
    "###############################################\n",
    "\n",
    "# REMEMBER THAT IF YOU WANT TO COMPARE THE INDEX THAT YOU GET WITH THE DATA SET,\n",
    "# YOU MUST ADD +1 TO THE INDEX VALUE. THE POSSIBLE NUMBERS RANGE FROM 0 TO 1296-1 (1295)\n",
    "# WHILE THE DATA SET STARTS FROM 1\n",
    "\n",
    "###############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eec6f3",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Preparing the datasets so that they are in the shape of (N, C, H, W)}}$\n",
    "\n",
    "$\\newline$\n",
    "N - number of images\n",
    "$\\newline$\n",
    "C - number of input channels \n",
    "$\\newline$\n",
    "H - height of our image in pixels\n",
    "$\\newline$\n",
    "W - width of our image in pixels \n",
    "$\\newline$\n",
    "Also changing the data types to tensors and then the type to float in order to match that of the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3982c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training photons\n",
    "training_photons = training_photons.reshape(648, 1, 4, 4)\n",
    "training_photons = torch.from_numpy(training_photons.astype(np.float32))\n",
    "training_position_arrays = torch.from_numpy(training_photon_arrays.astype(np.float32))\n",
    "\n",
    "# Validation photons\n",
    "validation_photons = validation_photons.reshape(324, 1, 4, 4)\n",
    "validation_photons = torch.from_numpy(validation_photons.astype(np.float32))\n",
    "validation_position_arrays = torch.from_numpy(validation_position_arrays.astype(np.float32))\n",
    "\n",
    "# Evaluation photons\n",
    "evaluating_photons = evaluating_photons.reshape(324, 1, 4, 4)\n",
    "evaluating_photons = torch.from_numpy(evaluating_photons.astype(np.float32))\n",
    "evaluation_position_arrays = torch.from_numpy(evaluation_position_arrays.astype(np.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef17a9",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Configuration of the model}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba225ce3",
   "metadata": {},
   "source": [
    "According to this stackexchange conversation\n",
    "\n",
    "https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks\n",
    "\n",
    "one epoch = one forward pass and one backward pass of all the training examples\n",
    "\n",
    "batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need\n",
    "\n",
    "number of iterations = number of passes, each pass using [batch size] number of examples. \n",
    "    To be clear, one pass = one forward pass + one backward pass (forward and backward passes are not counted as two different passes)\n",
    "\n",
    "For example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e94ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save configuration to file runs/2025-11-23_2038/impinging_position_config.yaml\n",
      "\n",
      "name: impinging_position\n",
      "file:\n",
      "  losses: runs/2025-11-23_2038/impinging_position_losses.csv\n",
      "  params: runs/2025-11-23_2038/impinging_position_params.pth\n",
      "  init_params: runs/2025-11-23_2038/impinging_position_init_params.pth\n",
      "  plots: runs/2025-11-23_2038/impinging_position_plots.png\n",
      "batch_size: 18\n",
      "train_size: 648\n",
      "test_size: 324\n",
      "val_size: 324\n",
      "monitor_step: 27\n",
      "delete: true\n",
      "frac: 0.015\n",
      "n_epochs: 200\n",
      "n_iters_per_epoch: 36\n",
      "n_iterations: 7200\n",
      "n_steps: 4\n",
      "n_iters_per_step: 1800\n",
      "base_lr: 0.001\n",
      "gamma: 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'impinging_position'\n",
    "\n",
    "# choose whether to create or load a configuration file\n",
    "load_existing_config = False\n",
    "\n",
    "if load_existing_config:\n",
    "    config = mlp.Config(f'{model_name}.yaml')\n",
    "else:\n",
    "    # create new config\n",
    "    config = mlp.Config(model_name)\n",
    "\n",
    "    n_images = 1296\n",
    "    batch_size = 18\n",
    "    n_iters_per_epoch = 36 # number of iterations per epoch\n",
    "    train_size = n_iters_per_epoch * batch_size\n",
    "    test_size = 324\n",
    "\n",
    "    val_size = n_images - train_size - test_size\n",
    "\n",
    "    config('batch_size', batch_size)\n",
    "    config('train_size', train_size)\n",
    "    config('test_size', test_size)\n",
    "    config('val_size', val_size)\n",
    "\n",
    "    config('monitor_step', 27) # set monitor training every n\n",
    "    config('delete', True) # delete losses file before training, if True\n",
    "    config('frac', 0.015) # save model if average loss decreases by more than frac percent\n",
    "\n",
    "    config('n_epochs', 200)\n",
    "    config('n_iters_per_epoch', n_iters_per_epoch)\n",
    "    config('n_iterations', config('n_epochs') * config('n_iters_per_epoch'))\n",
    "\n",
    "    config('n_steps', 4) # number of training steps\n",
    "    config('n_iters_per_step', config('n_iterations') // config('n_steps'))\n",
    "    \n",
    "    config('base_lr', 1.e-3) # initial learning rate\n",
    "    config('gamma', 0.8) # learning rate scale factor\n",
    "\n",
    "    print(f'\\nSave configuration to file {config.cfg_filename}\\n')\n",
    "    \n",
    "    config.save()\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db73912",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Getting our data turned into the proper data set so that it can be used with the data loaders}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de159538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n",
      "Dataset\n",
      "  shape of x: torch.Size([648, 1, 4, 4])\n",
      "  shape of y: torch.Size([648, 16])\n",
      "\n",
      "training data for validation\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 16])\n",
      "\n",
      "validation data\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 2])\n",
      "\n",
      "test data\n",
      "Dataset\n",
      "  shape of x: torch.Size([324, 1, 4, 4])\n",
      "  shape of y: torch.Size([324, 2])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tmp = torch.tensor(data[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(data[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(targets[start:end])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:147: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(data[indices])\n",
      "/home/tstuck/mlprojects/mlinphysics/mlinphysics/utils/data.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(targets[indices])\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dat)\n",
    "\n",
    "train_size = config('train_size')\n",
    "val_size = config('val_size')\n",
    "test_size = config('test_size')\n",
    "\n",
    "# training dataset (this defines the empirical risk to be minimized)\n",
    "print('training data')\n",
    "train_data = dat.Dataset(training_photons, start = 0, end = train_size, targets = training_position_arrays)\n",
    "\n",
    "# a random subset of the training data to check for overtraining\n",
    "# by comparing with the empirical risk from the validation set\n",
    "\n",
    "print('training data for validation')\n",
    "train_data_val = dat.Dataset(training_photons, start = 0, end = train_size, targets = training_position_arrays, random_sample_size = val_size)\n",
    "\n",
    "# validation dataset (for monitoring training)\n",
    "print('validation data')\n",
    "val_data = dat.Dataset(validation_photons, start = 0, end = val_size, targets = validation_position_arrays)\n",
    "\n",
    "# test dataset\n",
    "print('test data')\n",
    "test_data = dat.Dataset(evaluating_photons, start = 0, end = test_size, targets = evaluation_position_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe662",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Now we include the data loaders}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c798bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data loader\n",
      "train data loader for validation\n",
      "validation data loader\n",
      "test data loader\n"
     ]
    }
   ],
   "source": [
    "print('train data loader')\n",
    "train_loader = dt.DataLoader(train_data, batch_size = config('batch_size'), shuffle = True)\n",
    "\n",
    "print('train data loader for validation')\n",
    "train_loader_val = dt.DataLoader(train_data_val, batch_size = len(train_data_val))\n",
    "\n",
    "print('validation data loader')\n",
    "val_loader = dt.DataLoader(val_data, batch_size = len(val_data))\n",
    "\n",
    "print('test data loader')\n",
    "test_loader = dt.DataLoader(test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fde2074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb shape: torch.Size([18, 1, 4, 4])\n",
      "yb shape: torch.Size([18, 16])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_loader:\n",
    "    print(\"xb shape:\", xb.shape)\n",
    "    print(\"yb shape:\", yb.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16ad27",
   "metadata": {},
   "source": [
    "$\\underline{\\textbf{Now we build our model}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b2c8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding = 1, dropout = 0.08):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = 2 * padding + 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, \n",
    "                               kernel_size = kernel_size, stride = 1, padding = padding, padding_mode = 'replicate')\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class BeamPositionIdentifier(mlp.Model):\n",
    "    def __init__(self, image_size = 4, channels = (1, 8, 16), padding = 1, n_outputs = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        # number of convolutional layers\n",
    "        self.nlayers = len(channels) - 1\n",
    "\n",
    "        #building convolution layers\n",
    "        self.convs = nn.ModuleList(\n",
    "            [ConvBlock(channels[i], channels[i+1], padding)\n",
    "             for i in range(self.nlayers)])\n",
    "        \n",
    "        # computing size after convolutions\n",
    "        final_image_size = image_size\n",
    "        ninputs = channels[-1] * (final_image_size**2)\n",
    "\n",
    "        # Regression (Rather than using maxpool as we want to predict where the beam impinges upon the scintillating crystal (x,y) )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ninputs, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_outputs)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d260c",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Instantiate model}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5c9e732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeamPositionIdentifier(\n",
      "  (convs): ModuleList(\n",
      "    (0): ConvBlock(\n",
      "      (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.08, inplace=False)\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
      "      (relu): ReLU()\n",
      "      (dropout): Dropout(p=0.08, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (regressor): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "number of parameters:  17826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp)\n",
    "\n",
    "model = BeamPositionIdentifier().to(DEVICE)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print('number of parameters: ', mlp.number_of_parameters(model))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186ba54",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Mean Squared Error Loss function}}$\n",
    "\n",
    "$\\newline$\n",
    "Using the MSE rather than the Average cross entropy loss since we are using regression rather than classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd1354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredErrorLoss():\n",
    "    def __init__(self):\n",
    "        self.loss_function = nn.MSELoss()\n",
    "    def __call__(self, outputs, targets):\n",
    "        return self.loss_function(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8679161",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Instantiate training objects}}$\n",
    "\n",
    "$\\newline$\n",
    "1. optimizer\n",
    "$\\newline$\n",
    "2. scheduler\n",
    "$\\newline$\n",
    "3. objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edb4aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of milestones:          3\n",
      "\n",
      "Step | Milestone | LR\n",
      "-----------------------------\n",
      "   0 |         0 | 1.0e-03   \n",
      "-----------------------------\n",
      "   1 |      1800 | 8.0e-04   \n",
      "   2 |      3600 | 6.4e-04   \n",
      "   3 |      5400 | 5.1e-04   \n",
      "\n",
      "number of iterations:           7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = config('base_lr'))\n",
    "\n",
    "scheduler = mlp.get_steplr_scheduler(optimizer, config)\n",
    "\n",
    "objective = mlp.Objective(model, MeanSquaredErrorLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf8769",
   "metadata": {},
   "source": [
    "$\\underline{\\text{How we are defining accuracy}}$\n",
    "\n",
    "$\\newline$\n",
    "Since our output is continuous values, rather than the discrete categories as with assignment 3 we must redefine how we determine our model's accuracy. Let us consider the distance between predicted and the true value as our accuracy. The function accuracy takes the outputs from our model and our target values and spits out the average of the distance between the two vectors. So for example if we had (0.0, 0.1) as our output and (0.0, 0.0) as our true value for one run and we only consider one run. Then the accuracy mean that we have an average of 0.1 distance between our output and true target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "551c7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    \n",
    "    vector_distance = targets - outputs\n",
    "\n",
    "    distance = torch.sqrt(torch.sum(vector_distance**2))\n",
    "\n",
    "    return distance.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ca191",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Defining the Trainer}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96a6a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(objective, optimizer, scheduler, train_loader, train_small_loader, val_loader, config):\n",
    "    \n",
    "    # get configuration info\n",
    "    lossfile = config('file/losses')\n",
    "    paramsfile = config('file/params')\n",
    "    step = config('monitor_step')\n",
    "    delete = config('delete')\n",
    "    frac = config('frac')\n",
    "    nepochs = config('n_epochs')\n",
    "    niters = config('n_iterations')\n",
    "\n",
    "    # instantiate objects taht saves MSE losses to a csv file for realtime monitoring\n",
    "\n",
    "    losswriter = mon.LossWriter(niters, lossfile, step = step, delete = delete, frac = frac, model = objective.model, paramsfile = paramsfile)\n",
    "\n",
    "    # instantiate learning rate step scheduler\n",
    "    lrscheduler = mlp.LRStepScheduler(optimizer, scheduler)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # training loop\n",
    "    # ---------------------------------------\n",
    "    ii = -1\n",
    "\n",
    "    for epoch in range (nepochs):\n",
    "        for x, y in train_loader:\n",
    "            ii += 1\n",
    "\n",
    "            # set mode to training so that training-specific\n",
    "            # operations such as dropout, etc., are enabled.\n",
    "            objective.model.train()\n",
    "\n",
    "            # clear all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute empirical risk\n",
    "            R = objective(x,y)\n",
    "\n",
    "            # compute gradients\n",
    "            R.backward()\n",
    "\n",
    "            # take one step downhill in the empirical risk landscape\n",
    "            optimizer.step()\n",
    "\n",
    "            # check wheter to update learning rate\n",
    "            lrscheduler.step()\n",
    "\n",
    "            # I'm alive printout\n",
    "            if (ii % step == 0) or (ii == niters -1):\n",
    "                # compute average losses on training and validation data\n",
    "                t_loss = mlp.compute_avg_loss(objective, train_small_loader)\n",
    "                v_loss = mlp.compute_avg_loss(objective, val_loader)\n",
    "                # return current learning rate\n",
    "                lr = lrscheduler.lr()\n",
    "                # update loss file\n",
    "                losswriter(ii, t_loss, v_loss, lr, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b181096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tstuck/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([18, 16])) that is different to the input size (torch.Size([18, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m importlib.reload(mlp)\n\u001b[32m      2\u001b[39m importlib.reload(mon)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train(objective, optimizer, scheduler, train_loader, train_loader_val, val_loader, config)\n\u001b[32m      6\u001b[39m monitor = mon.Monitor(config(\u001b[33m'\u001b[39m\u001b[33mfile/losses\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      7\u001b[39m monitor.plot()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(objective, optimizer, scheduler, train_loader, train_small_loader, val_loader, config)\u001b[39m\n\u001b[32m     33\u001b[39m optimizer.zero_grad()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# compute empirical risk\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m R = objective(x,y)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# compute gradients\u001b[39;00m\n\u001b[32m     39\u001b[39m R.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mlprojects/mlinphysics/mlinphysics/nn.py:503\u001b[39m, in \u001b[36mObjective.forward\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[32m    502\u001b[39m     f = \u001b[38;5;28mself\u001b[39m.model(x)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.avgloss(f, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mMeanSquaredErrorLoss.__call__\u001b[39m\u001b[34m(self, outputs, targets)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs, targets):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss_function(outputs, targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/modules/loss.py:610\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.mse_loss(\u001b[38;5;28minput\u001b[39m, target, reduction=\u001b[38;5;28mself\u001b[39m.reduction)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/nn/functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = torch.broadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlp/lib/python3.13/site-packages/torch/functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _VF.broadcast_tensors(tensors)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (2) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "importlib.reload(mlp)\n",
    "importlib.reload(mon)\n",
    "\n",
    "train(objective, optimizer, scheduler, train_loader, train_loader_val, val_loader, config)\n",
    "\n",
    "monitor = mon.Monitor(config('file/losses'))\n",
    "monitor.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae339b7",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Compute accuracy on test set}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0401b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(config('file/params'))\n",
    "\n",
    "text_x, test_y = next(iter(test_loader))\n",
    "\n",
    "y_pred = model(test_x)\n",
    "\n",
    "acc = accuracy(y_pred, test_y)\n",
    "\n",
    "print('\\nPercentage of correct predictions: %8.1f%s' % (100*acc, '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e490e5",
   "metadata": {},
   "source": [
    "$\\underline{\\text{Plot confusion matrix}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dee48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_pred, y, t = 0.5, gfile = 'confusion_matrix.png'):\n",
    "    from sklearn.matrics import confusion_matrix\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true = y, y_pred = y_pred)\n",
    "\n",
    "    # Print the confusion matrix using Matplotlib\n",
    "    fig, ax = plt.subplots(figsize = (5,5))\n",
    "    ax.matshow(conf_matrix, cmap = plt.cm.rainbow, alpha = 0.8)\n",
    "\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x = j, y = i, s = conf_matrix[i, j], va = 'center', ha = 'center', size = 'x-large')\n",
    "\n",
    "    plt.xlabel('Predicted Labels', fontsize = 16)\n",
    "    plt.ylabel('True Labels', fontsize = 16)\n",
    "    plt.title(f'Confusion Matrix', fontsize = 16)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(gfile)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.argmax(y_pred.data.cpu().numpy(), axis = 1)\n",
    "\n",
    "y_true = test_y.data.cpu().numpy()\n",
    "\n",
    "plot_confusion_matrix(y_hat, y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
