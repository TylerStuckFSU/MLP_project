{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f08fd6",
   "metadata": {},
   "source": [
    "Google Colab Installation of mlinphysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23e70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running locally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLAB_FOLDER = 'MLP' # change as needed\n",
    "GITHUB_USER  = 'hbprosper'\n",
    "GITHUB_REPO  = 'mlinphysics'\n",
    "GITHUB_FOLDERS = ['mlinphysics']\n",
    "#------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    print('\\nGoogle Drive mounted\\n')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print('\\nRunning locally\\n')\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    MYDRIVE     = '/content/gdrive/MyDrive'\n",
    "    GITHUB_BASE = 'https://raw.githubusercontent.com'\n",
    "    MAIN        = 'refs/heads/main'\n",
    "    GITHUB_PATH = f'{MYDRIVE}/{COLAB_FOLDER}'\n",
    "    #------------------------------------------------------\n",
    "    %cd {GITHUB_PATH}\n",
    "    %rm -f {GITHUB_PATH}/clone2colab.ipynb\n",
    "    !wget -q {GITHUB_BASE}/{GITHUB_USER}/{GITHUB_REPO}/{MAIN}/clone2colab.ipynb\n",
    "    %run {GITHUB_PATH}/clone2colab.ipynb\n",
    "\n",
    "    %pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb438b52",
   "metadata": {},
   "source": [
    "Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8c306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "\n",
    "# module to access data in Hieracrchical Data Format (HDF or H5 format)\n",
    "import h5py\n",
    "\n",
    "# module to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# module to reimport Python modules\n",
    "import importlib\n",
    "\n",
    "# module for saving/loading serialized Python objects\n",
    "import joblib\n",
    "\n",
    "# module for shell utilities\n",
    "import shutil\n",
    "\n",
    "# ML in physics module\n",
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat\n",
    "import mlinphysics.utils.monitor as mon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095e404",
   "metadata": {},
   "source": [
    "Computational Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5950787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAvailable device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd31628",
   "metadata": {},
   "source": [
    "Loading the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8021704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1296, 16)\n"
     ]
    }
   ],
   "source": [
    "produced_photons_array = np.loadtxt('scan_CsI_Se82_master_produced_photon.dat')\n",
    "absorbed_photons_array = np.loadtxt('scan_CsI_Se82_master_absorbed_photon.dat')\n",
    "observed_photon_array_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_array.dat')\n",
    "observed_photon_total_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_total.dat')\n",
    "beam_position_array = np.loadtxt('scan_CsI_Se82_master_beam_position.dat')\n",
    "\n",
    "#Normalizing each PMT of the array to the total number of photons seen by the PMTs\n",
    "normalized_PMT_array = np.zeros((1296,16))\n",
    "\n",
    "for i in range (1296):\n",
    "    for m in range (16):\n",
    "        normalized_PMT_array[i][m] = observed_photon_array_array[i][m] / observed_photon_total_array[i]\n",
    "\n",
    "print (normalized_PMT_array.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea81c4",
   "metadata": {},
   "source": [
    "Separating the data sets into training, validating, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af24113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training idices:  [ 228  589 1271  857  509  398  386  266  776  911 1289 1252  225  716\n",
      "   81  891  298  534  612  865 1103  890  169  542  179 1031  177 1026\n",
      "  456  392  296 1071   89  448 1100  400  507  215  562 1259   70  995\n",
      "  744  399  931  477  710  133  944  706  649  918  337  805    2  265\n",
      " 1125  598  476 1072  491  331  607  349  987  642  605  482 1270  699\n",
      "  894  344  632  397 1067  802  688 1150 1180  464  898  366  167  801\n",
      "  644  378 1005  924  269 1019  199  746  573 1157  207  557  439  143\n",
      "  544  367 1146  203  526  192  478 1114  425  451  528  246  334  861\n",
      "  631  621 1287  892  142  243  516  340  525   88 1168  403  511  702\n",
      " 1135  377 1266  137  972  844  840 1240   66  816  691  160 1248 1207\n",
      "  515 1227  387  560   87  273   34  181 1282  856   43 1033  233  843\n",
      "  368 1267  113  563  727 1119 1129  283  486    6 1112  574  743 1087\n",
      "   16  136 1218  490 1029  821  635   73  497  806  380  479  583  555\n",
      "   98  452  412  383 1269  487  591 1278  493  722 1070  658 1101  322\n",
      "  550 1147  339  206 1069  151   29 1055  707  565  596  485   30 1158\n",
      "  304  708 1045  720 1034  171  935  921  152 1215 1037 1237 1255 1142\n",
      "  767  871 1263  676   57   94  834  956  472  830  455  992  444  780\n",
      "  730   99  922  155  882  117  748  916  184   64  100    5 1015 1254\n",
      " 1283 1264  930  435   14   48  118  665  663  111 1064  963  606  763\n",
      "  718 1060  901  932 1222 1187  120   36   65 1042  190 1228 1198   59\n",
      "  307 1193  408   17  753  798   44  498  783  860  122    3  685  356\n",
      "  904 1293  943  880   12  595 1056   13  216 1058  755  438   28 1232\n",
      "   80   54  934  318 1196  599 1077  257 1209  954  301  317  981 1172\n",
      " 1066 1213  784 1110 1171  815  959 1049 1123  960  148 1121 1136 1155\n",
      "  928 1046  786  312  690  998 1108  191 1098 1027  480  214   91  427\n",
      "  698  633  134  132  198 1000   68 1149  418  680  419  950  953  637\n",
      "  628  248 1020  543   37 1162  174  888 1078   76  164  636  694  186\n",
      " 1052  615  910 1256  569  791  238 1208  614   78 1244  842  420  712\n",
      "  158  597 1010  161 1257 1091 1291  173  765   95  660  572 1166  196\n",
      "  717 1124    8  661  725  547  253 1275  912  859  270  980  369  881\n",
      "  797  108  789 1178  588  778  907  701  529 1195  231  274]\n",
      "validation indices:  [ 985 1152  870  290   67  800  229 1192  395  469  333  611   26  820\n",
      "   63  741  936 1285  948  520  884  923 1011  793  651  803 1233  788\n",
      " 1089 1245  104 1159  329  288  664  986  539 1229  230 1217  506  593\n",
      "  394  236  764  287  326   20 1268  454  641  213  969  320  835  715\n",
      "  324  170  618  102  770  537  736  279   21 1261  364  105  390  110\n",
      "  988  129  363  545 1113  163  825  940 1216  836  345  695  810 1076\n",
      "  501  847 1234  189  619  667  696 1151  481  974  679  373  535 1074\n",
      " 1079  313  749 1024   61  446  567  305  782  872  771  757 1044  157\n",
      " 1214  564  558  219  866  831  673  862  551  430  361  799 1202  379\n",
      "  639  997  402  355 1177  629 1006  739  434  652 1167   62  194  124\n",
      " 1225 1092  218 1260 1247 1173 1104  429 1014 1199 1144  200  442  135\n",
      " 1274  814  240  131  908  431   31  358   40  261   52 1030  982  920\n",
      "  521  961 1262 1086 1223  211  733  762  647  285 1115 1126    4  522\n",
      "  640 1095  533  201  947  410  125  602 1279  819  561  256   55  348\n",
      "  603  854  773   23 1292  889 1002  738  323   97  103  251  584  672\n",
      " 1068  473  548  759  291  404  146  620  634  276    1  510  463  668\n",
      " 1035  468   85  445  484 1235  197  382  752 1001 1036  878  750  719\n",
      "  807  734  423  796  984 1083  342 1241  208  277  140  182  941  341\n",
      "  126  579  302  123   19   56 1088  242  362  852 1122 1040  638  576\n",
      "  648 1284  149 1219  527  153  586  975  955  964  729 1039  293  675\n",
      " 1109   90  703  101  518  868   92  976  411  202   41  848  128  365\n",
      "   39 1194 1130   42 1253  284 1165  239  156 1288 1127 1226  817  250\n",
      "  282  962  224  721  109  970 1140 1176  459 1022  777  624  354  428\n",
      "  682 1230  575  351  212  389  162  761   75  112   49  496  895  666\n",
      "  674   93  433  994 1258 1004  669 1175  505  875  622  221 1148  328\n",
      " 1220    0  609  945  864  384  289  853  758  401  267  570  732  879\n",
      "  422 1181  406  709 1017  310  902 1212  711  822  832  245  168 1163\n",
      "  973  295  742  450   79  116  654  210  432  424 1249  655   45  139\n",
      "  541  823  983  594   27 1224  775  193  873 1051  601  968  130  650\n",
      " 1201 1032 1081  683   72 1057  754   96 1053  183 1120 1273 1050  165\n",
      " 1063  556  896 1239 1191  839 1154  172  887  999  327 1084]\n"
     ]
    }
   ],
   "source": [
    "# generates a random sequence of integers from 0-1295\n",
    "randomized_indices = np.random.permutation(1296)\n",
    "\n",
    "training_indices = randomized_indices[0:432]\n",
    "validation_indices = randomized_indices[432:864]\n",
    "evaluating_model_indicies = randomized_indices[864:1296]\n",
    "\n",
    "# training, validation, and evaluation datasets\n",
    "training_photon_arrays = np.zeros((432,16))\n",
    "validation_photon_arrays = np.zeros((432,16))\n",
    "evaluation_photon_arrays = np.zeros((432,16))\n",
    "\n",
    "for i in range (432):\n",
    "    training_photon_arrays[i][:] = normalized_PMT_array[training_indices[i]][:]\n",
    "    validation_photon_arrays[i][:] = normalized_PMT_array[validation_indices[i]][:]\n",
    "    evaluation_photon_arrays[i][:] = normalized_PMT_array[evaluating_model_indicies[i]][:]\n",
    "\n",
    "#reshaping the normalized data so that we have 432 images of 4x4 pixels\n",
    "training_photons = training_photon_arrays.reshape(432, 4, 4)\n",
    "validation_photons = validation_photon_arrays.reshape(432, 4, 4)\n",
    "evaluating_photons = evaluation_photon_arrays.reshape(432, 4, 4)\n",
    "\n",
    "print('training idices: ',training_indices)\n",
    "print('validation indices: ',validation_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34036699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
