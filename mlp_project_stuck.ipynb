{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c264416",
   "metadata": {},
   "source": [
    "Goal is to develop machine learning code that takes input photon data from an array of my hodoscope and outputs where the beam impinged on the scintillating crystal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f08fd6",
   "metadata": {},
   "source": [
    "Google Colab Installation of mlinphysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23e70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running locally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLAB_FOLDER = 'MLP' # change as needed\n",
    "GITHUB_USER  = 'hbprosper'\n",
    "GITHUB_REPO  = 'mlinphysics'\n",
    "GITHUB_FOLDERS = ['mlinphysics']\n",
    "#------------------------------------------------------\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    print('\\nGoogle Drive mounted\\n')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print('\\nRunning locally\\n')\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    MYDRIVE     = '/content/gdrive/MyDrive'\n",
    "    GITHUB_BASE = 'https://raw.githubusercontent.com'\n",
    "    MAIN        = 'refs/heads/main'\n",
    "    GITHUB_PATH = f'{MYDRIVE}/{COLAB_FOLDER}'\n",
    "    #------------------------------------------------------\n",
    "    %cd {GITHUB_PATH}\n",
    "    %rm -f {GITHUB_PATH}/clone2colab.ipynb\n",
    "    !wget -q {GITHUB_BASE}/{GITHUB_USER}/{GITHUB_REPO}/{MAIN}/clone2colab.ipynb\n",
    "    %run {GITHUB_PATH}/clone2colab.ipynb\n",
    "\n",
    "    %pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb438b52",
   "metadata": {},
   "source": [
    "Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8c306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "\n",
    "# module to access data in Hieracrchical Data Format (HDF or H5 format)\n",
    "import h5py\n",
    "\n",
    "# module to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# module to reimport Python modules\n",
    "import importlib\n",
    "\n",
    "# module for saving/loading serialized Python objects\n",
    "import joblib\n",
    "\n",
    "# module for shell utilities\n",
    "import shutil\n",
    "\n",
    "# ML in physics module\n",
    "import mlinphysics.nn as mlp\n",
    "import mlinphysics.utils.data as dat\n",
    "import mlinphysics.utils.monitor as mon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095e404",
   "metadata": {},
   "source": [
    "Computational Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5950787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAvailable device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\n\\tAvailable device: {str(DEVICE):4s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd31628",
   "metadata": {},
   "source": [
    "Loading the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8021704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.5 -3.5 -8.   0.   0.   1. ]\n",
      " [-3.5 -3.3 -8.   0.   0.   1. ]\n",
      " [-3.5 -3.1 -8.   0.   0.   1. ]\n",
      " ...\n",
      " [ 3.5  3.1 -8.   0.   0.   1. ]\n",
      " [ 3.5  3.3 -8.   0.   0.   1. ]\n",
      " [ 3.5  3.5 -8.   0.   0.   1. ]]\n"
     ]
    }
   ],
   "source": [
    "produced_photons_array = np.loadtxt('scan_CsI_Se82_master_produced_photon.dat')\n",
    "absorbed_photons_array = np.loadtxt('scan_CsI_Se82_master_absorbed_photon.dat')\n",
    "observed_photon_array_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_array.dat')\n",
    "observed_photon_total_array = np.loadtxt('scan_CsI_Se82_master_observed_photon_total.dat')\n",
    "beam_position_array = np.loadtxt('scan_CsI_Se82_master_beam_position.dat')\n",
    "\n",
    "#Normalizing each PMT of the array to the total number of photons seen by the PMTs\n",
    "normalized_PMT_array = np.zeros((1296,16))\n",
    "\n",
    "for i in range (1296):\n",
    "    for m in range (16):\n",
    "        normalized_PMT_array[i][m] = observed_photon_array_array[i][m] / observed_photon_total_array[i]\n",
    "\n",
    "# print (normalized_PMT_array.shape)\n",
    "\n",
    "print(beam_position_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea81c4",
   "metadata": {},
   "source": [
    "Separating the data sets into training, validating, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af24113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training idices:  649\n",
      "training position [ 0.1 -3.3]\n",
      "training photons [0.05166662 0.04860686 0.04795064 0.05025786 0.05860697 0.05616966\n",
      " 0.05514111 0.05710189 0.06649824 0.06565226 0.06541435 0.06591317\n",
      " 0.07671038 0.07905066 0.07794018 0.07731917]\n"
     ]
    }
   ],
   "source": [
    "# generates a random sequence of integers from 0-1295\n",
    "randomized_indices = np.random.permutation(1296)\n",
    "\n",
    "training_indices = randomized_indices[0:432]\n",
    "validation_indices = randomized_indices[432:864]\n",
    "evaluating_model_indicies = randomized_indices[864:1296]\n",
    "\n",
    "# training, validation, and evaluation photon datasets\n",
    "training_photon_arrays = np.zeros((432,16))\n",
    "validation_photon_arrays = np.zeros((432,16))\n",
    "evaluation_photon_arrays = np.zeros((432,16))\n",
    "\n",
    "# training, validation, and evaluation position datasets\n",
    "training_position_arrays = np.zeros((432,2))\n",
    "validation_position_arrays = np.zeros((432,2))\n",
    "evaluation_position_arrays = np.zeros((432,2))\n",
    "\n",
    "for i in range (432):\n",
    "    # filling the photon datasets\n",
    "    training_photon_arrays[i][:] = normalized_PMT_array[training_indices[i]][:]\n",
    "    validation_photon_arrays[i][:] = normalized_PMT_array[validation_indices[i]][:]\n",
    "    evaluation_photon_arrays[i][:] = normalized_PMT_array[evaluating_model_indicies[i]][:]\n",
    "    \n",
    "    # filling the position datasets\n",
    "    training_position_arrays[i][:] = beam_position_array[training_indices[i], 0:2]\n",
    "    validation_position_arrays[i][:] = beam_position_array[validation_indices[i]][0:2]\n",
    "    evaluation_position_arrays[i][:] = beam_position_array[evaluating_model_indicies[i]][0:2]\n",
    "\n",
    "#reshaping the normalized data so that we have 432 images of 4x4 pixels\n",
    "training_photons = training_photon_arrays.reshape(432, 4, 4)\n",
    "validation_photons = validation_photon_arrays.reshape(432, 4, 4)\n",
    "evaluating_photons = evaluation_photon_arrays.reshape(432, 4, 4)\n",
    "\n",
    "print('training idices: ',training_indices[0])\n",
    "\n",
    "print('training position', training_position_arrays[0][:])\n",
    "\n",
    "print ('training photons', training_photon_arrays[0][:])\n",
    "###############################################\n",
    "\n",
    "# REMEMBER THAT IF YOU WANT TO COMPARE THE INDEX THAT YOU GET WITH THE DATA SET,\n",
    "# YOU MUST ADD +1 TO THE INDEX VALUE. THE POSSIBLE NUMBERS RANGE FROM 0 TO 1296-1 (1295)\n",
    "# WHILE THE DATA SET STARTS FROM 1\n",
    "\n",
    "###############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef17a9",
   "metadata": {},
   "source": [
    "Configuration of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba225ce3",
   "metadata": {},
   "source": [
    "According to this stackexchange conversation\n",
    "\n",
    "https://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks\n",
    "\n",
    "one epoch = one forward pass and one backward pass of all the training examples\n",
    "\n",
    "batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need\n",
    "\n",
    "number of iterations = number of passes, each pass using [batch size] number of examples. \n",
    "    To be clear, one pass = one forward pass + one backward pass (forward and backward passes are not counted as two different passes)\n",
    "\n",
    "For example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save configuration to file runs/2025-11-19_2100/impinging_position_config.yaml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'impinging_position'\n",
    "\n",
    "# choose whether to create or load a configuration file\n",
    "load_existing_config = False\n",
    "\n",
    "if load_existing_config:\n",
    "    config = mlp.Config(f'{model_name}.yaml')\n",
    "else:\n",
    "    # create new config\n",
    "    config = mlp.Config(model_name)\n",
    "\n",
    "    n_images = 1296\n",
    "    batch_size = 18\n",
    "    n_iters_per_epoch = 24 # number of iterations per epoch\n",
    "    train_size = n_iters_per_epoch * batch_size\n",
    "    test_size = 432\n",
    "\n",
    "    val_size = n_images - train_size - test_size\n",
    "\n",
    "    config('batch_size', batch_size)\n",
    "    config('train_size', train_size)\n",
    "    config('test_size', test_size)\n",
    "    config('val_size', val_size)\n",
    "\n",
    "    config('monitor_step', 27) # set monitor training every n\n",
    "    config('delete', True) # delete losses file before training, if True\n",
    "    config('frac', 0.015) # save model if average loss decreases by more than frac percent\n",
    "\n",
    "    config('n_epochs', 200)\n",
    "    config('n_iters_per_epoch', n_iters_per_epoch)\n",
    "    config('n_iterations', config('n_epochs') * config('n_iters_per_epoch'))\n",
    "\n",
    "    config('n_steps', 4) # number of training steps\n",
    "    config('n_iters_per_step', config('n_iterations') // config('n_steps'))\n",
    "    \n",
    "    config('base_lr', 1.e-3) # initial learning rate\n",
    "    config('gamma', 0.8) # learning rate scale factor\n",
    "\n",
    "    print(f'\\nSave configuration to file {config.cfg_filename}\\n')\n",
    "    \n",
    "    config.save()\n",
    "\n",
    "print(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
